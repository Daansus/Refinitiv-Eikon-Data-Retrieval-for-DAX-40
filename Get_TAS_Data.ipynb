{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFINITIV EIKON - TRADE AND QUOTES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import eikon as ek\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GERMAN MARKET SPECIFIC\n",
    "index = \"0#.GDAXI\"\n",
    "home_id = \"d.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHICH WEEK OF THE YEAR\n",
    "week_number = XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "weeks = 0\n",
    "days = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHICH MTFs\n",
    "biggest_mtfs = [\".DE\", \".DXE\", \".TQE\", \".AQE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET APP KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_key = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek.set_app_key(app_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek.set_timeout(1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET TRADING DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = f\"2024-W{week_number}\"\n",
    "end_date = datetime.strptime(d + '-1', \"%Y-W%W-%w\")\n",
    "end_date += + timedelta(days=4)\n",
    "end_date = end_date.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "start_date_dt = start_date_dt - relativedelta(weeks = weeks, days = days)\n",
    "start_date = datetime.strftime(start_date_dt, format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekdays_between_dates(start_date, end_date):\n",
    "    start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "    current_date = start_date\n",
    "    weekdays_list = []\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        if current_date.weekday() < 5:  \n",
    "            weekdays_list.append(current_date.strftime('%Y-%m-%d'))\n",
    "        current_date += timedelta(days = 1)\n",
    "\n",
    "    return weekdays_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_days = weekdays_between_dates(start_date = start_date, end_date = end_date)\n",
    "trading_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE AND SET PATH TO SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = Path(f\"TAS_{week_number}\")\n",
    "folder_name.mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = f\"./TAS_{week_number}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET CONSTITUENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_constituents = pd.read_pickle(\"index_constituents\")\n",
    "index_constituents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET FRAGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragmentation = pd.read_pickle(\"fragmentation\")\n",
    "fragmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constituents = fragmentation[\"ric\"].unique()\n",
    "i = 0\n",
    "for con in constituents:\n",
    "    print(f\" [{i}] {con}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET TAS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tas_data(ric, date):\n",
    "    def fetch_interval(ric, Sdate, Edate, interval):\n",
    "        # print(f\"               Start interval: {Sdate.split('T')[1][:8]} to {Edate.split('T')[1][:8]}\")\n",
    "        tries = 0\n",
    "        while tries < 3:\n",
    "            try:                \n",
    "                raw = ek.get_timeseries(rics = ric, start_date = Sdate, end_date = Edate, interval = \"tas\", raw_output = True)\n",
    "                fields = pd.DataFrame(raw[\"timeseriesData\"])[\"fields\"][0]\n",
    "                column_names = pd.DataFrame(fields)[\"name\"]\n",
    "                raw_data = pd.DataFrame(raw[\"timeseriesData\"])[\"dataPoints\"][0]\n",
    "                \n",
    "                trade_data_inc = pd.DataFrame(data = raw_data, columns = column_names)\n",
    "                trade_data_inc = trade_data_inc[['TIMESTAMP', 'EXCHTIME', 'TRDPRC_1', 'COUNT', \"MMT_CLASS\", \"TR_TRD_FLG\"]]\n",
    "                trade_data_inc.rename(columns={\"TRDPRC_1\": \"PRICE\", \"COUNT\": \"VOLUME\"}, inplace = True)\n",
    "                trade_data_inc = trade_data_inc[~trade_data_inc[\"PRICE\"].isna()]\n",
    "                \n",
    "                if len(trade_data_inc) >= 50000:\n",
    "                    new_Sdate = Sdate\n",
    "                    new_Edate = Edate\n",
    "                    new_interval = interval//2\n",
    "                    print(f\"                    Splitting interval for {ric}: {new_Sdate.split('T')[1][:8]} to {new_Edate.split('T')[1][:8]}\")\n",
    "                    mid_date = (datetime.strptime(new_Sdate, \"%Y-%m-%dT%H:%M:%S.%fZ\") + timedelta(seconds = new_interval)).strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")                \n",
    "                    trade_data_1 = fetch_interval(ric, new_Sdate, mid_date, new_interval)\n",
    "                    trade_data_2 = fetch_interval(ric, mid_date, new_Edate, new_interval)\n",
    "                    return pd.concat([trade_data_1, trade_data_2], ignore_index=True)\n",
    "                \n",
    "                # print(f\"               Done interval: {Sdate} to {Edate}\")\n",
    "                return trade_data_inc\n",
    "            \n",
    "            except Exception as e:\n",
    "                tries += 1\n",
    "                print(f\"                    Attempt {tries} failed with error: {e}\")\n",
    "                if tries >= 3:\n",
    "                    print(f\"                    Failed after {tries} attempts.\")\n",
    "                continue\n",
    "        \n",
    "        return pd.DataFrame()\n",
    "\n",
    "    date_conversion = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    Edate_dt = datetime(date_conversion.year, date_conversion.month, date_conversion.day, 15, 59, 59, 999999)\n",
    "    Sdate_dt = datetime(Edate_dt.year, Edate_dt.month, Edate_dt.day, 7, 0, 0, 0)\n",
    "    time_difference = (Edate_dt - Sdate_dt).total_seconds()\n",
    "\n",
    "    trade_data = pd.DataFrame()\n",
    "    intervals = 3600*9\n",
    "    Sdate_inc = Sdate_dt\n",
    "    \n",
    "    for sec in range(intervals, round(time_difference) + 1, intervals):\n",
    "        Edate_inc = Sdate_inc + timedelta(seconds = intervals)\n",
    "        Sdate = Sdate_inc.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        Edate = Edate_inc.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        \n",
    "        trade_data_inc = fetch_interval(ric, Sdate, Edate, intervals)\n",
    "        trade_data = pd.concat([trade_data, trade_data_inc], ignore_index = True)\n",
    "        \n",
    "        Sdate_inc = Edate_inc\n",
    "    \n",
    "    return trade_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "day_counter = 0\n",
    "tot_con_counter = 0\n",
    "\n",
    "print(f\"######################################## Start: GET TAS DATA ########################################\\n\")\n",
    "\n",
    "for day in trading_days:\n",
    "    trade_day = pd.DataFrame()\n",
    "    day_counter += 1\n",
    "    con_counter = 0\n",
    "    print(f\"#####################################################################################################\")\n",
    "    print(f\"Start day: {day} nr.{day_counter}/{len(trading_days)}\")\n",
    "    print(f\"#####################################################################################################\\n\")\n",
    "    \n",
    "    for con in constituents:\n",
    "        trade_con = pd.DataFrame()\n",
    "        tot_con_counter += 1\n",
    "        con_counter += 1\n",
    "        ric_counter = 0\n",
    "        print(f\"     Start constituent: {con} nr.{con_counter}/{len(constituents)}\")\n",
    "\n",
    "        fragmentation_con = list(fragmentation.loc[fragmentation[\"ric\"] == con, \"fragmentation\"])\n",
    "\n",
    "        for ric in fragmentation_con:\n",
    "            ric_counter += 1\n",
    "            # print(f\"          Start venue: {ric} nr.{ric_counter}/{len(fragmentation_con)}\")\n",
    "            \n",
    "            trade_ric = get_tas_data(ric, day)\n",
    "            trade_ric[\"RIC\"] = ric\n",
    "            trade_con = pd.concat([trade_con, trade_ric], ignore_index = True)\n",
    "\n",
    "            toc = time.time()\n",
    "            print(f\"          Done venue: {ric} nr.{ric_counter}/{len(fragmentation_con)} in {round(toc-tic,2)} seconds\")\n",
    "\n",
    "        # Save per day per constituent (200 files for 1 week)\n",
    "        # trade_con.to_csv(path_to_save + \"TAS_\" + con + \"_\" + day + \".csv\")\n",
    "        \n",
    "        toc = time.time()\n",
    "        print(f\"     Done constituent: {con} nr.{con_counter}/{len(constituents)} in {round(toc-tic,2)} seconds\\n\")\n",
    "        \n",
    "        estimated_total_time = ((toc-tic)/tot_con_counter) * (len(trading_days) * len(constituents))\n",
    "        print(\"---------------------------------------------------------------------------------------\")\n",
    "        print(f\"Progression: {round((tot_con_counter / (len(constituents) * len(trading_days))) * 100, 2)}%\")\n",
    "        print(f\"Estimated total time: {estimated_total_time // 3600} hour(s) and {(estimated_total_time % 3600) // 60} minute(s)\")\n",
    "        print(f\"Time started: {datetime.fromtimestamp(tic + 2 * 3600)}, Estimated finish: {datetime.fromtimestamp(tic + estimated_total_time + 2 * 3600)}\")\n",
    "        print(f\"Estimated time remaining: {(estimated_total_time - (toc - tic)) // 3600} hour(s) and {((estimated_total_time - (toc - tic)) % 3600) // 60} minute(s)\")\n",
    "        print(\"---------------------------------------------------------------------------------------\\n\")\n",
    "        \n",
    "        trade_day = pd.concat([trade_day, trade_con], ignore_index = True)\n",
    "\n",
    "    # Save per day (5 files for 1 week)\n",
    "    trade_day.to_csv(path_to_save + \"TAS_\" + day + \".csv\")\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(f\"#####################################################################################################\")\n",
    "    print(f\"Done day: {day} nr.{day_counter}/{len(trading_days)} in {round(toc-tic,2)} seconds\")\n",
    "    print(f\"#####################################################################################################\\n\")\n",
    "    \n",
    "print(f\"######################################## Done: GET TAS DATA #########################################\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
